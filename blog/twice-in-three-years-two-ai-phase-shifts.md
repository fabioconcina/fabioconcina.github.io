# Twice in Three Years: Two AI Phase Shifts

*February 2026*

In late 2022, when ChatGPT came out, it caught me off-guard. I don't remember what I asked first, but I remember that feeling. I was sitting on the sofa and I was shocked. I had been working in software for years, I knew roughly how neural networks worked, and still I was not prepared for what it felt like to have a computer just... understand what I was saying. Not through commands, not through syntax. Just language.

This was my first mental model adjustment.

The second time was in late 2025, when I first experimented with Claude Code running Opus 4.5. It was a different kind of shock, but with a similar strength. I described what I wanted to build, and the thing came back with a plan and started executing it. With no obvious errors. The steering from my side was minimal.  
I worked with GitHub Copilot for years, but the "Agent" mode always felt like a distraction, I was quicker just asking questions and integrating the suggestions myself.  
This time, it was quicker to make the agent do its work. Another mental model adjustment.

Two moments in three years. Both times I had the same reaction: this is new, this is a phase shift.

Having worked with these models for years, I knew the limitations. Models hallucinate. They are confidently wrong in ways a human would never be. And yet. This time hit different.

I don't think LLMs will get us to AGI. Not in their current form. There's a real debate about whether they truly understand or just simulate understanding very well. Most AI researchers seem to agree that scaling alone won't be enough: a [2025 AAAI survey](https://aaai.org/wp-content/uploads/2025/03/AAAI-2025-PresPanel-Report-FINAL.pdf) of 475 researchers found that 76% think scaling current approaches is "unlikely" or "very unlikely" to yield AGI. I believe something different is needed. A new architecture, a new paradigm, I don't know what. But LLMs are not the final thing. They are an incredible stepping stone.

A stepping stone that is already changing everything. Even with the limitations, the impact on how we work is real. Things that took my team days take hours now. Unit testing / documentation creation is trivial. Prototyping is absurdly fast. The distance between having an idea and seeing it running has collapsed in a way that was not imaginable three years ago.

This is exciting and terrifying at the same time. If you're a knowledge worker - and I am one - the tools that help you today will reshape what your job looks like tomorrow. I don't think this is decades away. It might be years. And most people I talk to, even in tech, don't seem to fully get it yet.

I don't have a conclusion. I'm not going to tell you AI will be a net benefit for the world or not. Nobody knows where this goes - not the people building these systems, not the people deploying them, and definitely not the people writing posts about them on X.

What I know is that twice in three years, a computer made me rethink what computers can do. I expect it will happen again. Probably sooner than I think.
